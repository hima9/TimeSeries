{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "LSTM_Mod.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDXFUYF1PYtK",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPU6BJ2BPbzd",
        "colab_type": "code",
        "outputId": "a4d856d5-634a-4651-9eef-bd4cabedf0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "JkwfHvK9PYtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "from sklearn import preprocessing, metrics\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set()\n",
        "from sklearn.model_selection import GroupKFold, KFold, TimeSeriesSplit\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU\n",
        "from tensorflow.keras.layers import Input, Flatten, Concatenate, BatchNormalization, Embedding\n",
        "from tensorflow.keras.losses import mse\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ww58gp3zPYtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w_size = 30 # LSTM window size\n",
        "batch_size=512\n",
        "epochs = 35\n",
        "span_lst = [7, 30, 90] # moving avarage time windows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h_hKRFTOPYt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sales = pd.read_csv('/content/drive/My Drive/m5-forecasting-accuracy/sales_train_validation.csv')# read sales data\n",
        "# categories are used for categorical model input\n",
        "categories = sales[['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']]# group categories\n",
        "sales['id'] = sales['id'].apply(lambda x: x[:-11]) # in id remove '_validation' so we get products with state\n",
        "ids = sales['id'].values\n",
        "\n",
        "sales = sales.iloc[:, -500:].T.reset_index()  #taking last 500 days for training and transposing it\n",
        "    \n",
        "sales.columns = ['d'] + list(ids)   #combine days and items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zTuwpwWlPYuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calendar = pd.read_csv('/content/drive/My Drive/m5-forecasting-accuracy/calendar.csv') # reading calendar data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DOj6AjIEPYua",
        "colab_type": "code",
        "outputId": "f3be8d26-f816-472f-fc1c-4297bb5001eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sales.d[0][2:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1414'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xVE9DBJPPYup",
        "colab_type": "code",
        "outputId": "e60cb33b-e459-4b88-d4d0-1bcdb4a21710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "calendar.d[2:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2          d_3\n",
              "3          d_4\n",
              "4          d_5\n",
              "5          d_6\n",
              "6          d_7\n",
              "         ...  \n",
              "1964    d_1965\n",
              "1965    d_1966\n",
              "1966    d_1967\n",
              "1967    d_1968\n",
              "1968    d_1969\n",
              "Name: d, Length: 1967, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xqIFOP2wPYuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subsetting by starting date here d_1414                             #'1414'\n",
        "calendar = calendar[calendar.d.apply(lambda x: int(x[2:])) >= int(sales.d[0][2:])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbHS2O47PYu4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Price Dataset\n",
        "\n",
        "* Transposing the long format into (weeks, items) dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "me1FdogWPYu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price = pd.read_csv('/content/drive/My Drive/m5-forecasting-accuracy/sell_prices.csv') #reading price data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fLzfQC4WPYu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the prices of items from starting day i.e 1414 and corresponding wm_yr_wk 11445\n",
        "price = price.loc[price.wm_yr_wk >= \\\n",
        "                    calendar[calendar.d == sales.d[0]]['wm_yr_wk'].values[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P18tHzP-PYvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price['id'] = price.apply(lambda x: x.item_id + '_' + x.store_id, axis=1) # combine item_id and store_id to get id as in sales\n",
        "price = price.pivot(index='wm_yr_wk', columns='id', values='sell_price') # form a table with wm_yr_wk as rows and id as cols\n",
        "price = calendar[['d','wm_yr_wk']].merge(price, how='inner', on=['wm_yr_wk']) # merge with calendar\n",
        "price.drop('wm_yr_wk', axis=1, inplace=True)\n",
        "price = price.loc[:, list(sales.columns)] #get the price for all items from starting day\n",
        "calendar.drop(['date','wm_yr_wk', 'weekday', 'd'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GSt91PmPYvH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Preprocessing\n",
        "\n",
        "*  Both sales and prices are log scaled and then standardized by global average and std.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "doYcymAnPYvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sales_log = np.log(sales.iloc[:, 1:].values + 1)\n",
        "sales_mean = np.mean(sales_log)\n",
        "sales_std = np.std(sales_log)\n",
        "sales.iloc[:, 1:] = (sales_log - sales_mean) / sales_std\n",
        "\n",
        "price_log = np.log(price.iloc[:, 1:].values)\n",
        "price_mean = np.mean(price_log)\n",
        "price_std = np.std(price_log)\n",
        "price.iloc[:, 1:] = (price_log - price_mean) / price_std\n",
        "\n",
        "sales.fillna(0, inplace=True)\n",
        "price.fillna(0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZklkNfTPYvO",
        "colab_type": "text"
      },
      "source": [
        "# Label encoding Categorical features for embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cK7Hx4OKPYvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_ft1 = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'] # from sales\n",
        "cat_ft2 = ['wday','month', 'year', 'event_name_1', 'event_type_1',\n",
        "           'event_name_2', 'event_type_2'] # from calendar\n",
        "\n",
        "category_counts = {}\n",
        "state_le = None\n",
        "\n",
        "def LabelEncoding(df, cat_ft):\n",
        "    \n",
        "    for col in cat_ft:\n",
        "        le = LabelEncoder()\n",
        "        df.loc[:, col] = df[col].astype(str)\n",
        "        df.loc[:, col] = le.fit_transform(df[col])\n",
        "        category_counts[col] = len(list(le.classes_))\n",
        "\n",
        "    return df\n",
        "\n",
        "categories = LabelEncoding(categories, cat_ft1)\n",
        "calendar = LabelEncoding(calendar, cat_ft2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CefPnMpjPYvU",
        "colab_type": "text"
      },
      "source": [
        "# SequenceGenerator for generating sequences similar to raw input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LWH3zjfcPYvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def moving_average(a, n): # calculating moving average\n",
        "    \n",
        "    if a.shape[0] >= n:\n",
        "        ret = np.cumsum(a, axis=0) #compute the cumulative sum of array elements \n",
        "        ret[n:, :] = ret[n:, :] - ret[:-n, :]\n",
        "        ret[:n-1, :] = np.zeros((n-1, ret.shape[1]))\n",
        "        return ret / n\n",
        "    else:\n",
        "        return np.zeros((a.shape[0], a.shape[1]))\n",
        "    \n",
        "class SequenceGenerator:\n",
        "    #calculate moving avg for 7 days in a window of 30 days with batch size of 32\n",
        "    def __init__(self, inputs, spans=[7], window=30, batch_size=32, infer=False): #infer=prediction for now let's assign it to false\n",
        "        self.sales = inputs[0]\n",
        "        self.prices = inputs[1]\n",
        "        self.categories = inputs[2]\n",
        "        self.calendar = inputs[3]\n",
        "        self.spans = spans\n",
        "        self.window = window\n",
        "        self.infer = infer\n",
        "        self.num_items = self.sales.shape[1]\n",
        "        \n",
        "        if self.infer:                                                        \n",
        "            self.batch_size = self.num_items                           # for training\n",
        "            self.num_days = self.sales.shape[0] - self.window + 1\n",
        "            self.steps_per_day = 1 \n",
        "            self.steps = 1\n",
        "        else:\n",
        "            self.batch_size = batch_size\n",
        "            self.num_days = self.sales.shape[0] - self.window          # for prediction\n",
        "            self.steps_per_day = self.num_items // self.batch_size + 1\n",
        "            self.steps = self.steps_per_day * self.num_days\n",
        "\n",
        "    def generate(self):\n",
        "        \n",
        "        ## for prediction, it starts from the the last starting date (no slides in days)\n",
        "        ## for training/validation, it starts from day 0\n",
        "        start_day = self.num_days - 1 if self.infer else 0\n",
        "            \n",
        "        while True:            \n",
        "            \n",
        "            for day in range(start_day, self.num_days):\n",
        "                    \n",
        "                s = self.sales[day:day+self.window, :].reshape(1, self.window, -1) #num of sales for window\n",
        "                p = self.prices[day:day+self.window, :]\\\n",
        "                    .reshape(1, self.window, -1)   #prices for window\n",
        "\n",
        "                X = np.concatenate((s,p),axis=0)\n",
        "\n",
        "                for span in self.spans:\n",
        "                    \n",
        "                    span_ = day if day < span else span\n",
        "\n",
        "                    ma = moving_average(self.sales[day-span_:day+self.window, :] #calculate mov avg for given span in that window\n",
        "                                        , n=span)[span_:, :]\\\n",
        "                        .reshape(1, self.window, -1)\n",
        "\n",
        "                    X = np.concatenate((X, ma),axis=0)\n",
        "\n",
        "                ## transposing (features, days, items) into (items, days, features)\n",
        "                X = np.transpose(X, (2,1,0)) \n",
        "\n",
        "                if not self.infer: #while predicting first output is considered as input to next day\n",
        "                    y = self.sales[day+self.window, :].reshape(-1,1) \n",
        "                    \n",
        "                for i in range(self.steps_per_day):\n",
        "                    \n",
        "                    ## if the batch go over the maxium item number, \n",
        "                    ## the batch_size will be truncated\n",
        "                    if (i+1)*self.batch_size > self.num_items:\n",
        "                        end = self.num_items\n",
        "                    else:\n",
        "                        end = (i+1)*self.batch_size\n",
        "                    \n",
        "                    ## categories has (items, features) shape\n",
        "                    ## only relevant item rows are fetched\n",
        "                    cat = self.categories[i*self.batch_size:end, :]\n",
        "                    state_id = cat[:, -1]\n",
        "                    # reshaping into (features, items, 1)\n",
        "                    cat = cat.T.reshape(cat.shape[1], cat.shape[0], 1)\n",
        "                    \n",
        "                    ## calender values are taken at prediction target date\n",
        "                    calen = self.calendar[day+self.window,:7].reshape(1,-1)\n",
        "                    calen = np.repeat(calen, end-i*self.batch_size, axis=0)\n",
        "                    calen = calen.T.reshape(calen.shape[1], calen.shape[0], 1)\n",
        "                    \n",
        "                    ## snap values are taken at prediction target date\n",
        "                    snap = self.calendar[day+self.window,7:].reshape(1,-1)\n",
        "                    snap = np.repeat(snap, end-i*self.batch_size, axis=0)\n",
        "                    # taking only relevant state's snap values for each row\n",
        "                    snap = snap[np.arange(len(snap)), state_id].reshape(-1,1)\n",
        "                    \n",
        "                    if self.infer:\n",
        "                        yield [X[i*self.batch_size: end]] + [j for j in cat]\\\n",
        "                                + [j for j in calen] + [snap]\n",
        "                    else:\n",
        "                        yield [X[i*self.batch_size: end]] + [j for j in cat] \\\n",
        "                              + [j for j in calen] + [snap],\\\n",
        "                              y[i*self.batch_size: end]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bMmqWODfPYvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(lstm_w_size, lstm_n_fts): #for lstm cell modeling\n",
        "    \n",
        "    ## Categorical embedding\n",
        "    cat_inputs = []\n",
        "    for cat in cat_ft1+cat_ft2:\n",
        "        cat_inputs.append(Input(shape=[1], name=cat))\n",
        "        \n",
        "    cat_embeddings = []\n",
        "    for i, cat in enumerate(cat_ft1+cat_ft2):\n",
        "        cat_embeddings.append(Embedding(category_counts[cat], \n",
        "                                        min(50, int(category_counts[cat]+1/ 2)), \n",
        "                                        name = cat + \"_embed\")(cat_inputs[i]))\n",
        "\n",
        "    cat_output = Concatenate()([Flatten()(cat_emb) \\\n",
        "                                          for cat_emb in cat_embeddings])\n",
        "    cat_output = Dropout(.7)(cat_output)\n",
        "    \n",
        "    # snap input\n",
        "    snap_input = Input(shape=[1])\n",
        "\n",
        "    ## LSTM\n",
        "    lstm_input = Input(shape=(lstm_w_size, lstm_n_fts)) #input shape\n",
        "    lstm_output = CuDNNLSTM(32)(lstm_input) #o/p shape is 32\n",
        "    \n",
        "    concat = Concatenate()([\n",
        "        lstm_output,\n",
        "        cat_output,\n",
        "        snap_input\n",
        "    ])\n",
        "        \n",
        "    dense_output = Dense(10,LeakyReLU(alpha=0.1))(concat)\n",
        "    out = Dense(1)(dense_output)\n",
        "    model = Model(inputs=[lstm_input] + cat_inputs + [snap_input],\n",
        "                  outputs=out)\n",
        "    model.compile(optimizer='rmsprop', loss='mse')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anI__oC1PYvc",
        "colab_type": "text"
      },
      "source": [
        "# Model Training - Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qW4hhrsNPYvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_training(inputs, cv, w_size=30, batch_size=32, epochs=10,\n",
        "                   early_stopping=10):\n",
        "\n",
        "    val_scores=[]\n",
        "    train_evals=[]\n",
        "    valid_evals=[]\n",
        "    best_epoch=[]\n",
        "\n",
        "    for idx, (train_index, val_index) in enumerate(cv.split(inputs[0])):\n",
        "        \n",
        "        if idx >= 1: # skipping the first 2 fold to save run time\n",
        "\n",
        "            #print(\"###### fold %d ######\" % (idx+1))\n",
        "            sales_train, sales_val = inputs[0][train_index, :],\\\n",
        "                                     inputs[0][val_index, :]\n",
        "            prices_train, prices_val = inputs[1][train_index, :],\\\n",
        "                                       inputs[1][val_index, :]\n",
        "            calendar_train, calendar_val = inputs[3][train_index, :],\\\n",
        "                                           inputs[3][val_index, :]\n",
        "            inputs_train = [sales_train, prices_train, inputs[2], calendar_train]\n",
        "            inputs_val = [sales_val, prices_val, inputs[2], calendar_val]\n",
        "\n",
        "            train_gen = SequenceGenerator(inputs_train, spans=span_lst,\n",
        "                                          window=w_size, batch_size=batch_size)\n",
        "            val_gen = SequenceGenerator(inputs_val, spans=span_lst, window=w_size,\n",
        "                                        batch_size=batch_size)\n",
        "\n",
        "            model = define_model(w_size, 2+len(span_lst))\n",
        "            early_stop = EarlyStopping(patience=early_stopping,\n",
        "                                       verbose=True,\n",
        "                                       restore_best_weights=True)\n",
        "\n",
        "            hist = model.fit_generator(train_gen.generate(),\n",
        "                      validation_data=val_gen.generate(),\n",
        "                      epochs=epochs,\n",
        "                      steps_per_epoch=train_gen.steps, \n",
        "                      validation_steps=val_gen.steps, \n",
        "                      callbacks=[early_stop],\n",
        "                      verbose=0)\n",
        "\n",
        "            val_scores.append(np.min(hist.history['val_loss']))\n",
        "            train_evals.append(hist.history['loss'])\n",
        "            valid_evals.append(hist.history['val_loss'])\n",
        "\n",
        "            best_epoch.append(np.argmin(hist.history['val_loss']) + 1)\n",
        "    \n",
        "    print('### CV scores by fold ###')\n",
        "    for i in range(2, cv.get_n_splits(sales)):\n",
        "        print(f'fold {i+1}: {val_scores[i-2]:.4f} at epoch {best_epoch[i-2]}')\n",
        "    print('CV mean score: {0:.4f}, std: {1:.4f}'\\\n",
        "          .format(np.mean(val_scores), np.std(val_scores)))\n",
        "    \n",
        "    return best_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fsdQS7rHPYvg",
        "colab_type": "code",
        "outputId": "c3d9cd0e-2ee8-49d9-d385-e19a32348f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "sales = sales.iloc[:,1:].values\n",
        "price = price.iloc[:,1:].values\n",
        "categories = categories.values\n",
        "calendar = calendar.values\n",
        "inputs = [sales, price, categories, calendar]\n",
        "\n",
        "\n",
        "cv = TimeSeriesSplit(n_splits=4)\n",
        "best_epoch = model_training(inputs, cv, w_size=w_size, \n",
        "                                batch_size=batch_size, \n",
        "                                epochs=epochs, early_stopping=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-c1860f62f00b>:36: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00020: early stopping\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00018: early stopping\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00016: early stopping\n",
            "### CV scores by fold ###\n",
            "fold 3: 0.4651 at epoch 15\n",
            "fold 4: 0.4753 at epoch 13\n",
            "CV mean score: 0.4757, std: 0.0088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEZAH7QiPYvk",
        "colab_type": "text"
      },
      "source": [
        "# Model Training without CV split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SxTqRjw2PYvl",
        "colab_type": "code",
        "outputId": "c8ea71e3-e41a-450a-d307-abbd20e037f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "train_gen = SequenceGenerator(inputs, spans=span_lst, window=w_size,\n",
        "                              batch_size=batch_size)\n",
        "model = define_model(w_size, 2+len(span_lst))\n",
        "hist = model.fit_generator(train_gen.generate(),\n",
        "                           epochs=best_epoch[-1],\n",
        "                           steps_per_epoch=train_gen.steps,\n",
        "                           verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 3min 28s, sys: 5min 33s, total: 1h 9min 2s\n",
            "Wall time: 49min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa7TmJ-EPYvp",
        "colab_type": "text"
      },
      "source": [
        "# Predictions for Submission\n",
        "\n",
        "* Each prediction will be used for the model input for the next day prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rwONP_SyPYvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subsetting len-w_size-90: as we need the first 90 days \n",
        "# prior to the LSTM window to calculate 90 days moving avarage\n",
        "sales_test = sales[sales.shape[0]-w_size-90:, :]\n",
        "prices_test = price[sales.shape[0]-w_size-90:, :]\n",
        "calendar_test = calendar[sales.shape[0]-w_size-90:, :]\n",
        "test_inputs = [sales_test, prices_test, categories, calendar_test]\n",
        "\n",
        "for i in range(28):\n",
        "    \n",
        "    test_gen = SequenceGenerator(test_inputs, spans=span_lst, \n",
        "                                 window=w_size, infer=True)\n",
        "    test_iter = test_gen.generate()\n",
        "    X = next(test_iter)\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # appending predicted sales to the input and shifting it by 1\n",
        "    sales_test = np.append(sales_test, y_pred.reshape(1,-1), axis=0)[1:, :]\n",
        "    prices_test = prices_test[1:, :]\n",
        "    calendar_test = calendar_test[1:, :]\n",
        "    test_inputs = [sales_test, prices_test, categories, calendar_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IHdZIc-lPYvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sales_test = np.exp((sales_test * sales_std) + sales_mean) - 1\n",
        "sales_test = np.maximum(sales_test, np.zeros(sales_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b9sZYAbQPYvw",
        "colab_type": "code",
        "outputId": "8267c252-18f7-4497-c1e6-3c10b392d088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "submission = pd.read_csv('/content/drive/My Drive/m5-forecasting-accuracy/sample_submission.csv')\n",
        "\n",
        "submission.iloc[:len(submission)//2, 1:] = sales_test[-28:, :].T\n",
        "    \n",
        "submission.to_csv('/content/drive/My Drive/m5-forecasting-accuracy/submission.csv', index=False)\n",
        "submission.head()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "item_id (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dept_id (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "cat_id (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "store_id (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "state_id (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "wday (InputLayer)               [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "month (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "year (InputLayer)               [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "event_name_1 (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "event_type_1 (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "event_name_2 (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "event_type_2 (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_id_embed (Embedding)       (None, 1, 50)        152450      item_id[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dept_id_embed (Embedding)       (None, 1, 7)         49          dept_id[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cat_id_embed (Embedding)        (None, 1, 3)         9           cat_id[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "store_id_embed (Embedding)      (None, 1, 10)        100         store_id[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "state_id_embed (Embedding)      (None, 1, 3)         9           state_id[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "wday_embed (Embedding)          (None, 1, 7)         49          wday[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "month_embed (Embedding)         (None, 1, 12)        144         month[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "year_embed (Embedding)          (None, 1, 3)         9           year[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "event_name_1_embed (Embedding)  (None, 1, 31)        961         event_name_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "event_type_1_embed (Embedding)  (None, 1, 5)         25          event_type_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "event_name_2_embed (Embedding)  (None, 1, 2)         4           event_name_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "event_type_2_embed (Embedding)  (None, 1, 2)         4           event_type_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_36 (Flatten)            (None, 50)           0           item_id_embed[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_37 (Flatten)            (None, 7)            0           dept_id_embed[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_38 (Flatten)            (None, 3)            0           cat_id_embed[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_39 (Flatten)            (None, 10)           0           store_id_embed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_40 (Flatten)            (None, 3)            0           state_id_embed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_41 (Flatten)            (None, 7)            0           wday_embed[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_42 (Flatten)            (None, 12)           0           month_embed[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_43 (Flatten)            (None, 3)            0           year_embed[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_44 (Flatten)            (None, 31)           0           event_name_1_embed[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_45 (Flatten)            (None, 5)            0           event_type_1_embed[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_46 (Flatten)            (None, 2)            0           event_name_2_embed[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_47 (Flatten)            (None, 2)            0           event_type_2_embed[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 30, 5)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 135)          0           flatten_36[0][0]                 \n",
            "                                                                 flatten_37[0][0]                 \n",
            "                                                                 flatten_38[0][0]                 \n",
            "                                                                 flatten_39[0][0]                 \n",
            "                                                                 flatten_40[0][0]                 \n",
            "                                                                 flatten_41[0][0]                 \n",
            "                                                                 flatten_42[0][0]                 \n",
            "                                                                 flatten_43[0][0]                 \n",
            "                                                                 flatten_44[0][0]                 \n",
            "                                                                 flatten_45[0][0]                 \n",
            "                                                                 flatten_46[0][0]                 \n",
            "                                                                 flatten_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_3 (CuDNNLSTM)        (None, 32)           4992        input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 135)          0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 168)          0           cu_dnnlstm_3[0][0]               \n",
            "                                                                 dropout_3[0][0]                  \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 10)           1690        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            11          dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 160,506\n",
            "Trainable params: 160,506\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVYvH18amPUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}